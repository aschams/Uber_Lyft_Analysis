{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import math\n",
    "import numpy as np\n",
    "import scipy\n",
    "import os\n",
    "import time\n",
    "import seaborn as sns\n",
    "from scipy.stats import binom, hypergeom\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.stats.api as sms\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cab_rides.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['day']=df.time_stamp.apply(lambda x: time.strftime('%a', time.localtime(x/1000)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AMPM']=df.time_stamp.apply(lambda x: time.strftime('%p', time.localtime(x/1000)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['month']=df.time_stamp.apply(lambda x: time.strftime('%b', time.localtime(x/1000)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time']=df.time_stamp.apply(lambda x: time.strftime('%H', time.localtime(x/1000)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['week']=df.time_stamp.apply(lambda x: time.strftime('%U', time.localtime(x/1000)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['date_time']=df.time_stamp.apply(lambda x: time.strftime('%Y-%m-%d %H', time.localtime(x/1000)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.date_time.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.date_time.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.week.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.week.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['merge_date'] = df.source.astype(str) +\" - \"+ df.date_time.astype(\"str\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('weather.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['date_time']=df1.time_stamp.apply(lambda x: time.strftime('%Y-%m-%d %H', time.localtime(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.date_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the datasets to refelect same time for a location\n",
    "df1['merge_date'] = df1.location.astype(str) +\" - \"+ df1.date_time.astype(\"str\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = df.merge(df1, how='inner', left_on = ['merge_date'], right_on=['merge_date'], suffixes=('_c','_w'))\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.drop_duplicates(subset='id', keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['time'] = merged_df['time'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['rushhr'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.loc[(merged_df.time > 7) & (merged_df.time < 10), 'rushhr'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.loc[(merged_df.time > 17) & (merged_df.time < 22), 'rushhr'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.groupby('time')['rushhr'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.get_dummies(merged_df, columns=[\n",
    "                           'cab_type', 'destination', 'source', 'name', 'day', 'AMPM', 'month', 'week'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['Black'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['Black'] = merged_df['name_Black'] + merged_df['name_Black SUV'] + \\\n",
    "    merged_df['name_Lux Black'] + merged_df['name_Lux Black XL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged_df.groupby('Black')['name_Black','name_Black SUV','name_Lux Black','name_Lux Black XL'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['sports'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.loc[(merged_df.date_time_c.str.contains('2018-12-02')) & (merged_df.AMPM_PM == 1), 'sports'] = 1\n",
    "merged_df.loc[(merged_df.date_time_c.str.contains('2018-11-30')) & (merged_df.AMPM_PM == 1), 'sports'] = 1\n",
    "merged_df.loc[(merged_df.date_time_c.str.contains('2018-12-06')) & (merged_df.AMPM_PM == 1), 'sports'] = 1\n",
    "merged_df.loc[(merged_df.date_time_c.str.contains('2018-12-10')) & (merged_df.AMPM_PM == 1), 'sports'] = 1\n",
    "merged_df.loc[(merged_df.date_time_c.str.contains('2018-12-14')) & (merged_df.AMPM_PM == 1), 'sports'] = 1\n",
    "merged_df.loc[(merged_df.date_time_c.str.contains('2018-11-29')) & (merged_df.AMPM_PM == 1), 'sports'] = 1\n",
    "merged_df.loc[(merged_df.date_time_c.str.contains('2018-12-01')) & (merged_df.AMPM_PM == 1), 'sports'] = 1\n",
    "merged_df.loc[(merged_df.date_time_c.str.contains('2018-12-08')) & (merged_df.AMPM_PM == 1), 'sports'] = 1\n",
    "merged_df.loc[(merged_df.date_time_c.str.contains('2018-12-11')) & (merged_df.AMPM_PM == 1), 'sports'] = 1\n",
    "merged_df.loc[(merged_df.date_time_c.str.contains('2018-12-16')) & (merged_df.AMPM_PM == 1), 'sports'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sportdf = merged_df.groupby('date_time_c')['sports'].sum()\n",
    "with pd.option_context(\"display.max_rows\", 1000):\n",
    "    display(sportdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(merged_df.isnull(),axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.rain.fillna(0, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['rain_d']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.loc[(merged_df.rain) > 0, 'rain_d'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[merged_df.rain_d == 0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['wkndPM']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.loc[(merged_df.day_Fri == 1) & (merged_df.AMPM_PM == 1), 'wkndPM'] = 1\n",
    "merged_df.loc[(merged_df.day_Sat == 1) & (merged_df.AMPM_PM == 1), 'wkndPM'] = 1\n",
    "merged_df.loc[(merged_df.day_Sun == 1) & (merged_df.AMPM_PM == 1), 'wkndPM'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wkndPMdf = merged_df.groupby('merge_date')['wkndPM'].sum()\n",
    "with pd.option_context(\"display.max_rows\", 1000):\n",
    "    display(wkndPMdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.drop(['time_stamp_c', 'time_stamp_w', 'date_time_c',\n",
    "                'date_time_w', 'id', 'product_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['base_price'] = merged_df.price/merged_df.surge_multiplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['distance', 'price', 'temp', 'clouds', 'pressure', 'rain', 'humidity', 'wind', 'base_price', 'surge_multiplier']\n",
    "for n in names:\n",
    "    merged_df[f'n{n}'] = (merged_df[n] - merged_df[n].mean())/(merged_df[n].max() - merged_df[n].min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['distance', 'price', 'temp', 'clouds', 'pressure', 'rain', 'humidity', 'wind', 'base_price', 'surge_multiplier']\n",
    "for n in names:\n",
    "    merged_df[f'l{n}'] = np.log(merged_df[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "merged_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.drop(['lrain', 'lclouds'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.lsurge_multiplier.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('data/merged_df_Tues.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.read_csv('data/merged_df_Tues.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.plotting.scatter_matrix(merged_df[['lprice',\n",
    "       'ldistance','lbase_price','ltemp']], alpha=.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.plotting.scatter_matrix(merged_df[['lprice', 'lclouds',\n",
    "       'lpressure', 'lrain', 'lhumidity', 'lwind']], alpha = .05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = merged_df[['distance', 'price', 'surge_multiplier', 'merge_date', 'temp',\n",
    "       'location', 'clouds', 'pressure', 'rain', 'humidity', 'wind',\n",
    "       'cab_type_Lyft', 'cab_type_Uber']].corr()\n",
    "ax = sns.heatmap(\n",
    "    corr, \n",
    "    vmin=-1, vmax=1, center=0,\n",
    "    cmap=sns.diverging_palette(20, 220, n=200),\n",
    "    square=True\n",
    ")\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=45,\n",
    "    horizontalalignment='right'\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = merged_df[['destination_Back Bay',\n",
    "       'destination_Beacon Hill', 'destination_Boston University',\n",
    "       'destination_Fenway', 'destination_Financial District',\n",
    "       'destination_Haymarket Square', 'destination_North End',\n",
    "       'destination_North Station', 'destination_Northeastern University',\n",
    "       'destination_South Station', 'destination_Theatre District',\n",
    "       'destination_West End']].corr()\n",
    "ax = sns.heatmap(\n",
    "    corr, \n",
    "    vmin=-1, vmax=1, center=0,\n",
    "    cmap=sns.diverging_palette(20, 220, n=200),\n",
    "    square=True\n",
    ")\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=45,\n",
    "    horizontalalignment='right'\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spec 1: logged numerical and all raw one hot encoded dummies minus one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = merged_df[['ldistance','ltemp', 'clouds',\n",
    "       'lpressure', 'rain', 'lhumidity', 'lwind',\n",
    "       'lsurge_multiplier', 'cab_type_Uber', 'destination_Back Bay',\n",
    "       'destination_Boston University',\n",
    "       'destination_Fenway', 'destination_Financial District',\n",
    "       'destination_Haymarket Square', 'destination_North End',\n",
    "       'destination_North Station', 'destination_Northeastern University',\n",
    "       'destination_South Station', 'destination_Theatre District',\n",
    "       'destination_West End', 'source_Back Bay', \n",
    "       'source_Boston University', 'source_Fenway',\n",
    "       'source_Financial District', 'source_Haymarket Square',\n",
    "       'source_North End', 'source_North Station',\n",
    "       'source_Northeastern University', 'source_South Station',\n",
    "       'source_Theatre District', 'source_West End', 'name_Black',\n",
    "       'name_Black SUV', 'name_Lux', 'name_Lux Black', 'name_Lux Black XL',\n",
    "       'name_Lyft', 'name_Lyft XL', 'name_Shared', 'name_Taxi',\n",
    "       'name_UberPool', 'name_UberX', 'name_UberXL', 'day_Fri',\n",
    "       'day_Mon', 'day_Sat', 'day_Thu', 'day_Tue', 'day_Wed',\n",
    "       'AMPM_PM', 'month_Dec', 'week_47', 'week_48',\n",
    "       'week_49', 'sports', 'wkndPM']]\n",
    "X = sm.add_constant(X)\n",
    "Y = merged_df['lprice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test1, Y_train1, Y_test1 = train_test_split(X,Y, test_size = .2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.OLS(Y_train1, X_train1).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res = model.resid # residuals\n",
    "fig = sm.qqplot(res, stats.t, fit=True, line=str(45))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso & Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "lasso1 = LassoCV()\n",
    "lasso1.fit(X_train1, Y_train1)\n",
    "preds1 = lasso1.predict(X_test)\n",
    "lasso1.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lasso1.score(X_test1, Y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso1_res = Y_test1 - preds1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mse1 = mean_squared_error(Y_test1, preds1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.exp(mse1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(Y_test1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(mse1)/np.exp(Y_test1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(lasso1_res, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(Y_test1, preds1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "sm.qqplot(lasso1_res, stats.t, fit=True, line=str(45))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Y_test1, lasso1_res, 'k.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.loc[res[res > 0.15].index, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "ridge1 = RidgeCV()\n",
    "ridge1.fit(X_train1, Y_train1)\n",
    "preds1r = ridge1.predict(X_test1)\n",
    "ridge1.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ridge1.score(X_test1, Y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge1_res = Y_test1 - preds1r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mse1r = mean_squared_error(Y_test1, preds1r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.exp(mse1r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(Y_test1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(mse1r)/np.exp(Y_test1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(ridge1_res, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(Y_test1, preds1r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sm.qqplot(ridge1_res, stats.t, fit=True, line=str(45))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spec 2: normalized numerical and all raw one hot encoded dummies minus one and rain dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = merged_df[['ldistance','ltemp', 'clouds',\n",
    "       'lpressure', 'rain', 'lhumidity', 'lwind',\n",
    "       'lsurge_multiplier', 'cab_type_Uber', 'destination_Back Bay',\n",
    "       'destination_Boston University',\n",
    "       'destination_Fenway', 'destination_Financial District',\n",
    "       'destination_Haymarket Square', 'destination_North End',\n",
    "       'destination_North Station', 'destination_Northeastern University',\n",
    "       'destination_South Station', 'destination_Theatre District',\n",
    "       'destination_West End', 'source_Back Bay', \n",
    "       'source_Boston University', 'source_Fenway',\n",
    "       'source_Financial District', 'source_Haymarket Square',\n",
    "       'source_North End', 'source_North Station',\n",
    "       'source_Northeastern University', 'source_South Station',\n",
    "       'source_Theatre District', 'source_West End', 'name_Black',\n",
    "       'name_Black SUV', 'name_Lux', 'name_Lux Black', 'name_Lux Black XL',\n",
    "       'name_Lyft', 'name_Lyft XL', 'name_Shared', 'name_Taxi',\n",
    "       'name_UberPool', 'name_UberX', 'name_UberXL', 'day_Fri',\n",
    "       'day_Mon', 'day_Sat', 'day_Thu', 'day_Tue', 'day_Wed',\n",
    "       'AMPM_PM', 'month_Dec', 'week_47', 'week_48',\n",
    "       'week_49', 'sports', 'wkndPM', 'rain_d']]\n",
    "X2 = sm.add_constant(X2)\n",
    "Y2 = merged_df['lprice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train2, X_test2, Y_train2, Y_test2 = train_test_split(X2,Y2, test_size = .2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = sm.OLS(Y_train2, X_train2).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "lasso2 = LassoCV()\n",
    "lasso2.fit(X_train2, Y_train2)\n",
    "preds2 = lasso2.predict(X_test2)\n",
    "lasso2.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lasso2.score(X_test2, Y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso2_res = Y_test2 - preds2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mse2 = mean_squared_error(Y_test2, preds2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.exp(mse2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(Y_test2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.exp(mse2)/np.exp(Y_test2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(Y_test2 - preds2, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(Y_test2, preds2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "sm.qqplot(lasso2_res, stats.t, fit=True, line=str(45))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "ridge2 = RidgeCV()\n",
    "ridge2.fit(X_train2, Y_train2)\n",
    "preds2r = ridge2.predict(X_test2)\n",
    "ridge2.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ridge2.score(X_test2, Y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge2_res = Y_test2 - preds2r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mse2r = mean_squared_error(Y_test2, preds2r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.exp(mse2r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(Y_test2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.exp(mse2r)/np.exp(Y_test2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(ridge2_res, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(Y_test2, preds2r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.qqplot(ridge2_res, stats.t, fit=True, line=str(45))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spec 3: normalized numerical and rain and selected dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3 = merged_df[['ldistance','ltemp', 'clouds',\n",
    "       'lpressure', 'rain', 'lhumidity', 'lwind',\n",
    "       'lsurge_multiplier', \n",
    "       'cab_type_Uber', 'destination_Back Bay','source_Beacon Hill',\n",
    "       'destination_Haymarket Square', 'destination_Northeastern University',\n",
    "       'source_Back Bay', 'day_Fri',\n",
    "       'AMPM_PM', 'month_Dec', 'sports', 'wkndPM', 'rain_d', 'Black']]\n",
    "X3 = sm.add_constant(X3)\n",
    "Y3 = merged_df['lprice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train3, X_test3, Y_train3, Y_test3 = train_test_split(X3,Y3, test_size = .2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = sm.OLS(Y_train3, X_train3).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "lasso3 = LassoCV()\n",
    "lasso3.fit(X_train3, Y_train3)\n",
    "preds3 = lasso3.predict(X_test3)\n",
    "lasso3.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lasso3.score(X_test3, Y_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso3_res = Y_test3 - preds3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mse3 = mean_squared_error(Y_test3, preds3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.exp(mse3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(Y_test3).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.exp(mse3)/np.exp(Y_test3).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(lasso3_res, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(Y_test3, preds3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "sm.qqplot(lasso3_res, stats.t, fit=True, line=str(45))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "ridge3 = RidgeCV()\n",
    "ridge3.fit(X_train3, Y_train3)\n",
    "preds3r = ridge3.predict(X_test3)\n",
    "ridge3.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ridge3.score(X_test3, Y_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge3_res = Y_test3 - preds3r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mse3r = mean_squared_error(Y_test3, preds3r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.exp(mse3r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(Y_test3).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.exp(mse3r)/np.exp(Y_test3).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(ridge3_res, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(Y_test3, ridge3_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sm.qqplot(ridge3_res, stats.t, fit=True, line=str(45))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spec 4: split black and not black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X4 = merged_df[(merged_df.Black == 0)][['ldistance','ltemp', 'clouds',\n",
    "       'lpressure', 'rain', 'lhumidity', 'lwind',\n",
    "       'lsurge_multiplier', \n",
    "       'cab_type_Uber', 'destination_Back Bay','source_Beacon Hill',\n",
    "       'destination_Haymarket Square', 'destination_Northeastern University',\n",
    "       'source_Back Bay', 'day_Fri',\n",
    "       'AMPM_PM', 'month_Dec', 'sports', 'wkndPM', 'rain_d']]\n",
    "X4 = sm.add_constant(X4)\n",
    "Y4 = merged_df[(merged_df.Black == 0)]['lprice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train4, X_test4, Y_train4, Y_test4 = train_test_split(X4,Y4, test_size = .2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = sm.OLS(Y_train4, X_train4).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "lasso4 = LassoCV()\n",
    "lasso4.fit(X_train4, Y_train4)\n",
    "preds4 = lasso4.predict(X_test4)\n",
    "lasso4.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lasso4.score(X_test4, Y_test4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso4_res = Y_test4 - preds4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mse4 = mean_squared_error(Y_test4, preds4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.exp(mse4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(Y_test4).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.exp(mse4)/np.exp(Y_test4).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(lasso4_res, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(Y_test4, preds4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "sm.qqplot(lasso4_res, stats.t, fit=True, line=str(45))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Y_test4, lasso4_res, 'k.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "ridge4 = RidgeCV()\n",
    "ridge4.fit(X_train4, Y_train4)\n",
    "preds4r = ridge4.predict(X_test4)\n",
    "ridge4.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ridge4.score(X_test4, Y_test4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_res4 = Y_test4 - preds4r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mse4r = mean_squared_error(Y_test4, preds4r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.exp(mse4r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(Y_test4).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.exp(mse4r)/np.exp(Y_test4).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(ridge_res4, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(Y_test4, preds4r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sm.qqplot(ridge_res4, stats.t, fit=True, line=str(45))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X4b = merged_df[(merged_df.Black == 1)][['ldistance','ltemp', 'clouds',\n",
    "       'lpressure', 'rain', 'lhumidity', 'lwind',\n",
    "       'lsurge_multiplier', \n",
    "       'cab_type_Uber', 'destination_Back Bay','source_Beacon Hill',\n",
    "       'destination_Haymarket Square', 'destination_Northeastern University',\n",
    "       'source_Back Bay', 'day_Fri',\n",
    "       'AMPM_PM', 'month_Dec', 'sports', 'wkndPM', 'rain_d']]\n",
    "X4b = sm.add_constant(X4b)\n",
    "Y4b = merged_df[(merged_df.Black == 1)]['lprice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train4b, X_test4b, Y_train4b, Y_test4b = train_test_split(X4b,Y4b, test_size = .2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train4b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test4b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train4b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test4b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4b = sm.OLS(Y_train4b, X_train4b).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4b.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "lasso4b = LassoCV()\n",
    "lasso4b.fit(X_train4b, Y_train4b)\n",
    "preds4b = lasso4b.predict(X_test4b)\n",
    "lasso4b.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lasso4b.score(X_test4b, Y_test4b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso4b_res = Y_test4b - preds4b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mse4b = mean_squared_error(Y_test4b, preds4b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.exp(mse4b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(Y_test4b).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.exp(mse4b)/np.exp(Y_test4b).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(lasso4b_res, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(Y_test4b, preds4b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "sm.qqplot(lasso4b_res, stats.t, fit=True, line=str(45))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Y_test4b, lasso4b_res, 'k.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "ridge4b = RidgeCV()\n",
    "ridge4b.fit(X_train4b, Y_train4b)\n",
    "preds4br = ridge4.predict(X_test4b)\n",
    "ridge4b.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ridge4b.score(X_test4b, Y_test4b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_res4b = Y_test4b - preds4br"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mse4br = mean_squared_error(Y_test4b, preds4br)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.exp(mse4br)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(Y_test4b).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.exp(mse4br)/np.exp(Y_test4b).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(ridge_res4b, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(Y_test4b, preds4br)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sm.qqplot(ridge_res4b, stats.t, fit=True, line=str(45))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LassoCV\n",
    "embeded_lr_selector = SelectFromModel(LassoCV(), max_features=20)\n",
    "embeded_lr_selector.fit(X_train, Y_train)\n",
    "\n",
    "embeded_lr_support = embeded_lr_selector.get_support()\n",
    "embeded_lr_feature = X_train.loc[:,embeded_lr_support].columns.tolist()\n",
    "print(str(len(embeded_lr_feature)), 'selected features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeded_lr_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet_df = merged_df[['distance', 'surge_multiplier', 'temp', 'clouds', 'pressure', \n",
    "                        'rain', 'humidity', 'wind', 'name_Black', 'name_Black SUV', \n",
    "                        'name_Lux', 'name_Lux Black', 'name_Lux Black XL', 'name_Lyft', \n",
    "                        'name_Lyft XL', 'name_Shared', 'name_Taxi', 'name_UberPool', 'name_UberX', \n",
    "                        'name_UberXL', 'name_WAV', 'destination_Back Bay', 'destination_Beacon Hill', \n",
    "                        'destination_Boston University', 'destination_Fenway', 'destination_Financial District',\n",
    "                        'destination_Haymarket Square', 'destination_North End', 'destination_North Station', \n",
    "                        'destination_Northeastern University', 'destination_South Station', \n",
    "                        'destination_Theatre District', 'destination_West End', 'source_Back Bay', \n",
    "                        'source_Beacon Hill', 'source_Boston University', 'source_Fenway',\n",
    "                        'source_Financial District', 'source_Haymarket Square',\n",
    "                        'source_North End', 'source_North Station',\n",
    "                        'source_Northeastern University', 'source_South Station',\n",
    "                         'source_Theatre District', 'source_West End','price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX= dataSet_df[['distance', 'surge_multiplier', 'temp', 'clouds', 'pressure', \n",
    "                        'rain', 'humidity', 'wind', 'name_Black', 'name_Black SUV', \n",
    "                        'name_Lux', 'name_Lux Black', 'name_Lux Black XL', 'name_Lyft', \n",
    "                        'name_Lyft XL', 'name_Shared', 'name_Taxi', 'name_UberPool', 'name_UberX', \n",
    "                        'name_UberXL', 'name_WAV', 'destination_Back Bay', 'destination_Beacon Hill', \n",
    "                        'destination_Boston University', 'destination_Fenway', 'destination_Financial District',\n",
    "                        'destination_Haymarket Square', 'destination_North End', 'destination_North Station', \n",
    "                        'destination_Northeastern University', 'destination_South Station', \n",
    "                        'destination_Theatre District', 'destination_West End', 'source_Back Bay', \n",
    "                        'source_Beacon Hill', 'source_Boston University', 'source_Fenway',\n",
    "                        'source_Financial District', 'source_Haymarket Square',\n",
    "                        'source_North End', 'source_North Station',\n",
    "                        'source_Northeastern University', 'source_South Station',\n",
    "                         'source_Theatre District', 'source_West End']]\n",
    "YY = dataSet_df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(XX.values, YY.values, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=4, random_state=137, n_estimators=1000)\n",
    "regr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_rf = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fimpDict = {}\n",
    "for fimp in list(zip(XX.columns, regr.feature_importances_)):\n",
    "    print(fimp)\n",
    "    fimpDict.update({fimp[0]:fimp[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kk = list(fimpDict.keys())\n",
    "vv = list(fimpDict.values())\n",
    "\n",
    "\n",
    "fimpDF = pd.DataFrame({'features':kk,\n",
    "                      'importance':vv})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fimpDF.sort_values(by='importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_test-y_rf, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr2 = RandomForestRegressor(max_depth=5, random_state=137, n_estimators=2000)\n",
    "regr2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fimpDict2 = {}\n",
    "for fimp in list(zip(XX.columns, regr2.feature_importances_)):\n",
    "    print(fimp)\n",
    "    fimpDict2.update({fimp[0]:fimp[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kk = list(fimpDict.keys())\n",
    "vv = list(fimpDict.values())\n",
    "\n",
    "\n",
    "fimpDF = pd.DataFrame({'features':kk,\n",
    "                      'importance':vv})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fimpDF.sort_values(by='importance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## haven't run yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.read_csv('merged_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df[(merged_df.price < 40) & (merged_df.price >5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = merged_df.drop(['price', 'location', 'merge_date',\n",
    "                    'lprice', 'distance', 'cab_type_Lyft', 'destination_Back Bay',\n",
    "                    'source_Back Bay', 'name_Taxi'], axis=1)\n",
    "X = sm.add_constant(X)\n",
    "X.reset_index(drop=True,inplace=True)\n",
    "Y = pd.DataFrame(norm_Y.T)\n",
    "Y.reset_index(drop=True,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_array = np.array(merged_df['price'])\n",
    "norm_y = preprocessing.normalize([y_array])\n",
    "merged_df['nnprice'] = pd.DataFrame(norm_y.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_array = np.array(merged_df['distance'])\n",
    "norm_d = preprocessing.normalize([d_array])\n",
    "merged_df['ndistance'] = pd.DataFrame(norm_d.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_array = np.array(merged_df['temp'])\n",
    "norm_t = preprocessing.normalize([t_array])\n",
    "merged_df['ntemp'] = pd.DataFrame(norm_t.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_array = np.array(merged_df['clouds'])\n",
    "norm_c = preprocessing.normalize([c_array])\n",
    "merged_df['nclouds'] = pd.DataFrame(norm_c.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_array = np.array(merged_df['pressure'])\n",
    "norm_p = preprocessing.normalize([p_array])\n",
    "merged_df['npressure'] = pd.DataFrame(norm_p.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_array = np.array(merged_df['rain'])\n",
    "norm_r = preprocessing.normalize([r_array])\n",
    "merged_df['nrain'] = pd.DataFrame(norm_r.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_array = np.array(merged_df['humidity'])\n",
    "norm_h = preprocessing.normalize([h_array])\n",
    "merged_df['nhumidity'] = pd.DataFrame(norm_h.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_array = np.array(merged_df['wind'])\n",
    "norm_w = preprocessing.normalize([w_array])\n",
    "merged_df['nwind'] = pd.DataFrame(norm_w.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_11 = LogisticRegressionCV(penalty='l1', solver='liblinear', cv=3, max_iter=500, class_weight= 'balanced',)\n",
    "lr_l2 = LogisticRegressionCV(penalty='l2', cv=3, max_iter=500 , class_weight= 'balanced')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_11_rs = LogisticRegressionCV(penalty='l1', solver='liblinear', cv=3, max_iter=500, class_weight= 'balanced')\n",
    "lr_l2_rs = LogisticRegressionCV(penalty='l2', cv=3, max_iter=500 , class_weight= 'balanced')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ptw/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "X = merged_df[['ldistance','ltemp', 'clouds',\n",
    "       'lpressure', 'rain', 'lhumidity', 'lwind',\n",
    "       'cab_type_Uber', 'destination_Back Bay',\n",
    "       'destination_Boston University',\n",
    "       'destination_Fenway', 'destination_Financial District',\n",
    "       'destination_Haymarket Square', 'destination_North End',\n",
    "       'destination_North Station', 'destination_Northeastern University',\n",
    "       'destination_South Station', 'destination_Theatre District',\n",
    "       'destination_West End', 'source_Back Bay', \n",
    "       'source_Boston University', 'source_Fenway',\n",
    "       'source_Financial District', 'source_Haymarket Square',\n",
    "       'source_North End', 'source_North Station',\n",
    "       'source_Northeastern University', 'source_South Station',\n",
    "       'source_Theatre District', 'source_West End', 'name_Black',\n",
    "       'name_Black SUV', 'name_Lux', 'name_Lux Black', 'name_Lux Black XL',\n",
    "       'name_Lyft', 'name_Lyft XL', 'name_Shared', 'name_Taxi',\n",
    "       'name_UberPool', 'name_UberX', 'name_UberXL', 'day_Fri',\n",
    "       'day_Mon', 'day_Sat', 'day_Thu', 'day_Tue', 'day_Wed',\n",
    "       'AMPM_PM', 'month_Dec', 'week_47', 'week_48',\n",
    "       'week_49', 'sports', 'wkndPM']]\n",
    "X = sm.add_constant(X)\n",
    "y = (merged_df.surge_multiplier != 1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lr, X_test_lr, y_train_lr, y_test_lr = train_test_split(X, y, test_size=0.2, stratify = y, random_state=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(508193, 56)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_lr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(508193,)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_lr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16707"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_lr.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03182891979424652"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16707/(508193 +16707)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0: 492018, 1: 16175})\n",
      "Resampled dataset shape Counter({0: 492018, 1: 492018})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE # doctest: +NORMALIZE_WHITESPACE\n",
    "X_train_lr, y_train_lr = make_classification(\n",
    "weights=[(1-0.03182891979424652),0.03182891979424652], n_samples=508193, random_state=10)\n",
    "print('Original dataset shape %s' % Counter(y_train_lr))\n",
    "#Original dataset shape Counter({1: 900, 0: 100})\n",
    "smote = SMOTE(random_state=42)\n",
    "X_res, y_res = smote.fit_resample(X_train_lr, y_train_lr)\n",
    "print('Resampled dataset shape %s' % Counter(y_res))\n",
    "#Resampled dataset shape Counter({0: 900, 1: 900})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE()\n",
    "X_train_resampled, y_train_resampled = smote.fit_sample(X_train_lr, y_train_lr) \n",
    "print(pd.Series(y_train_resampled).value_counts()) #Preview synthetic sample class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "492018"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_res.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "984036"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.44394941, -0.82096294,  0.08421542, ..., -1.83925523,\n",
       "         0.0142563 , -1.15818895],\n",
       "       [-1.1650269 ,  0.66919584,  1.28568035, ..., -0.91044961,\n",
       "         0.7023219 ,  0.17114202],\n",
       "       [ 0.53061168, -0.37411333, -1.10438309, ..., -0.25392073,\n",
       "         0.26273281,  0.7347992 ],\n",
       "       ...,\n",
       "       [-0.76330262, -0.48496726, -0.43266563, ..., -0.90468592,\n",
       "         0.71833107, -1.08092946],\n",
       "       [ 1.00763883,  0.07307482, -0.82933737, ..., -1.5824914 ,\n",
       "         2.22916499, -1.65733527],\n",
       "       [-0.57769539, -0.87331701, -0.60782999, ...,  1.0582369 ,\n",
       "         0.96258308,  0.87263583]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ptw/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "lr_11.fit(X_train_lr, y_train_lr)\n",
    "lr_l2.fit(X_train_lr, y_train_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr_11_rs.fit(X_train_resampled, y_train_resampled)\n",
    "lr_l2_rs.fit(X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12005604136986517"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_11.score(X_test_lr, y_test_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12005604136986517"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_l2.score(X_test_lr, y_test_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrl1_predict = lr_11.predict(X_test_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrl2_predict = lr_l2.predict(X_test_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_comp_df = pd.DataFrame([lrl1_predict, lrl2_predict]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    115973\n",
       "0     11076\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_comp_df[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    115973\n",
       "0     11076\n",
       "Name: 1, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_comp_df[1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.score(X_test_lr, y_test_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.26767738e-01,  9.33651929e-02,  7.19170866e-02,\n",
       "         1.56491091e-01, -3.70477106e-02,  1.59259975e-01,\n",
       "         3.65987952e-02, -7.25788113e-03, -1.01583444e-02,\n",
       "        -2.41955590e-02,  1.50505581e-01, -9.21788006e-02,\n",
       "         9.46629573e-03, -8.47026277e-02,  1.56904791e-01,\n",
       "        -1.95840651e-01,  6.46528255e-02,  9.26780043e-02,\n",
       "         1.84912457e-01,  6.44239631e-02,  8.89098930e-02,\n",
       "        -1.99536458e-01,  1.23041745e-01, -6.47818080e-03,\n",
       "         1.26760318e-01,  4.33513535e-01, -8.35720192e-02,\n",
       "        -1.66845799e-02,  8.01683951e-02, -1.26965424e-01,\n",
       "        -4.14342944e-02,  2.75065511e-02, -7.87246163e-02,\n",
       "         3.33456999e-03,  2.65702870e-02, -1.58023600e-02,\n",
       "         1.35063153e-01, -1.56109819e-01, -1.19888535e-01,\n",
       "         3.71194184e-02,  1.12803089e-01,  1.21865396e+01,\n",
       "        -7.56848746e+00, -6.27802907e-02,  7.01325220e-02,\n",
       "        -1.61160602e-03, -8.58752259e-02,  3.13369215e-02,\n",
       "         1.86573548e-01,  3.01091005e-02,  2.84874267e-02,\n",
       "        -6.64098972e-02, -1.22742250e-01, -1.25970127e-01,\n",
       "        -1.80400052e-03, -5.29846421e-02]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_11.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.58949223e-01,  1.07029012e-01,  1.05240796e-01,\n",
       "         1.81099296e-01, -5.55793263e-02,  1.79639071e-01,\n",
       "         4.59531651e-02,  3.29606661e-03, -1.73515324e-02,\n",
       "        -3.91446686e-02,  5.07516041e-01, -1.11596635e-01,\n",
       "         7.10946644e-03, -1.00143197e-01,  1.92421179e-01,\n",
       "        -2.41529924e-01,  7.61339925e-02,  9.69368342e-02,\n",
       "         2.17961846e-01,  7.79267936e-02,  9.81895461e-02,\n",
       "        -2.40272299e-01,  1.48019840e-01, -6.11987139e-04,\n",
       "         1.51943901e-01, -2.50960586e+00, -8.80760614e-02,\n",
       "        -2.26950992e-02,  9.64393282e-02, -1.77302712e-01,\n",
       "        -5.30276797e-02,  2.46027021e-02, -1.08042824e-01,\n",
       "         2.43856208e-02,  4.87024015e-02, -1.91734656e-02,\n",
       "         1.68747320e-01, -1.90739918e-01, -1.40594472e-01,\n",
       "         3.35954270e-02,  1.46172331e-01,  1.09332105e+01,\n",
       "        -1.07411834e+01, -7.41909373e-02,  7.43379111e-02,\n",
       "        -2.23918499e-03, -1.09993965e-01,  3.52700713e-02,\n",
       "         2.16750882e-01,  3.77337960e-02,  3.62620127e-02,\n",
       "        -8.40574370e-02, -1.48358132e-01, -1.54693895e-01,\n",
       "        -5.06435427e-03, -5.78589843e-02]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_l2.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_l2.coef_[abs(lr_l2.coef_)>.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_11.coef_[abs(lr_11.coef_)>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "probs = lr.predict_proba(X_test_lr)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test_lr, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "probs = lr_11.predict_proba(X_test_lr)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test_lr, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "probs = lr_l2.predict_proba(X_test_lr)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test_lr, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
